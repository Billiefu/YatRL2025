# Reinforcement Learning & Game Theory  [SYSU CSE 2025-1]

> Copyright © 2025 Fu Tszkok.

## Repository Description

This repository meticulously curates and preserves all assignments and their corresponding code implementations for the **Reinforcement Learning & Game Theory** course offered at Sun Yat-sen University during the 2024-1 semester. The course is instructed by Prof. Chen Xu, whose pedagogy guides students progressively from the foundational concepts and principles of reinforcement learning to the study of its most advanced and state-of-the-art models. In adherence to copyright, this repository does not contain any lecture slides (PPTs) or other related course materials.

## Copyright Statement

All original code in this repository is licensed under the **[GNU Affero General Public License v3](LICENSE)**, with additional usage restrictions specified in the **[Supplementary Terms](ADDITIONAL_TERMS.md)**. Users must expressly comply with the following conditions:

* **Commercial Use Restriction**
  Any form of commercial use, integration, or distribution requires prior written permission.
* **Academic Citation Requirement**When referenced in research or teaching, proper attribution must include:

  * Original author credit
  * Link to this repository
* **Academic Integrity Clause**
  Prohibits submitting this code (or derivatives) as personal academic work without explicit authorization.

The full legal text is available in the aforementioned license documents. Usage of this repository constitutes acceptance of these terms.

## Repository Contents

* Homework1 - Grid Maze Solver
* Homework2 - Cliff Walk with TD Learning
* Homework3 - DRL Application (Gomoku with AlphaZero)

Additionally, in the root directory of this repository, you will find the repository's documentation (`Readme.md`), its environment configuration file (`environment.yml`), and the open-source license (`LICENSE`).

## Environment

To run the code in this repository, you need to set up the required environment. Although configuring a Conda environment is not particularly difficult, this repository provides a pre-defined environment setup stored in the `environment.yml` file located in the root directory.

To configure the environment, ensure that you have Anaconda or Miniconda installed. After installing the environment, switch to the current directory in the command line (cmd) and run the following command:

```shell
conda env create -f environment.yml
```

If there are no issues, the environment should be created successfully. You can then activate the environment by running the following command in the command line:

```shell
conda activate YatRL
```

If you are using PyCharm, VSCode, or other IDEs, you can configure the environment directly within the IDE and run the relevant programs from there.

## Acknowledgments

I would like to express my sincere gratitude to Prof. *Chen Xu* for his mentorship in the field of reinforcement learning; his expert insights have been instrumental to my academic journey. I am equally thankful to my fiancée, Ms. *Ma Yujie*, for her unwavering support and quiet encouragement. It has been nearly two years since I entered the field of reinforcement learning, and I wish to thank all the teachers and classmates who have helped me along the way.

## Contact & Authorization

For technical inquiries, academic collaboration, or commercial licensing, contact the copyright holder via:

* **Academic Email**: `futk@mail2.sysu.edu.cn`
* **Project Discussions**: [Github Issues](https://github.com/Billiefu/YatRL2025/issues)
